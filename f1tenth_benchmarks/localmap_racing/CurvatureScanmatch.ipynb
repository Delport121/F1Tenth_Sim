{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trajectory_planning_helpers as tph\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import LineCollection\n",
    "from f1tenth_benchmarks.utils.MapData import MapData\n",
    "from f1tenth_benchmarks.utils.track_utils import RaceTrack, CentreLine\n",
    "from trajectory_planning_helpers.calc_head_curv_num import calc_head_curv_num\n",
    "from scipy import interpolate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_corners(kappa, lower_threshold=0.2, corner_threshold=0.6):\n",
    "    kappa = np.abs(kappa)\n",
    "    corner_count = 0\n",
    "    valid_crossing = True\n",
    "    corner_crossings = []\n",
    "    for i in range(len(kappa) -1):\n",
    "        if kappa[i] > corner_threshold and valid_crossing:\n",
    "            corner_count += 1\n",
    "            corner_crossings.append(i)\n",
    "            valid_crossing = False\n",
    "        if kappa[i] < lower_threshold:\n",
    "            valid_crossing = True\n",
    "\n",
    "    return corner_count, corner_crossings\n",
    "\n",
    "def measure_straight_section(kappa, el_lengths_full, threshold=0.1):\n",
    "    kappa = np.abs(kappa)\n",
    "    count = np.where(kappa < threshold)[0]\n",
    "    straight_length = np.sum(el_lengths_full[count])\n",
    "\n",
    "    return straight_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map name                    AUT         ESP         GBR         MCO\n",
      "Track length [m]      94.901903  236.928941  201.837814  178.708344\n",
      "Straight length [\\%]  64.919514   58.981774   59.452985   60.597009\n",
      "Number of corners      7.000000    7.000000    7.000000   16.000000\n"
     ]
    }
   ],
   "source": [
    "map_file_list = glob.glob(f\"../../maps/*_centerline.csv\")\n",
    "\n",
    "map_data = []\n",
    "for map_file in map_file_list:\n",
    "    track = np.loadtxt(map_file, delimiter=',', skiprows=1)\n",
    "\n",
    "    map_name = map_file.split(\"/\")[-1].split(\"_\")[0]\n",
    "    el_lengths = np.linalg.norm(np.diff(track[:, :2], axis=0), axis=1)\n",
    "    track_length = np.sum(el_lengths)\n",
    "\n",
    "    psi, kappa = tph.calc_head_curv_num.calc_head_curv_num(track[:, :2], el_lengths, False)\n",
    "\n",
    "    last_el = np.linalg.norm(track[0, :2] - track[-1, :2])\n",
    "    full_el = np.append(el_lengths, last_el)\n",
    "    straight_length = measure_straight_section(kappa, full_el)\n",
    "    corner_count, corner_crossings = count_corners(kappa)\n",
    "\n",
    "\n",
    "    mini_dict = {\n",
    "        \"MapName\": map_name, \n",
    "        \"TrackLength\": track_length, \n",
    "        \"StraightLength\": straight_length/track_length*100,\n",
    "        \"CornerCount\": corner_count,\n",
    "        }\n",
    "    map_data.append(mini_dict)\n",
    "\n",
    "df = pd.DataFrame(map_data)\n",
    "df = df.sort_values(by=[\"MapName\"])\n",
    "neat_names = [\"Map name\", \"Track length [m]\", \"Straight length [\\%]\", \"Number of corners\"]\n",
    "df.rename(columns=dict(zip(df.columns, neat_names)), inplace=True)\n",
    "df = df.set_index('Map name', drop=True).T\n",
    "df.rename(columns=str.upper, inplace=True)\n",
    "#df.to_latex(\"../Data/MapInfo/MapTable.tex\", float_format=\"%.2f\")\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map name                     AUT         ESP         GBR         MCO\n",
      "Track length [m]       94.901903  236.928941  201.837814  178.708344\n",
      "Total curvature        82.632845  158.752590  156.193379  171.391243\n",
      "Total corrected [rad]  16.562513   31.948041   31.538246   34.358199\n",
      "Mean curvature          0.174331    0.134308    0.155108    0.192143\n",
      "Straight length [m]    64.919514   58.981774   59.452985   60.597009\n",
      "Corner count            7.000000    7.000000    7.000000   16.000000\n",
      "  Map name  Track length [m]  Total curvature  Total corrected [rad]  \\\n",
      "0      AUT         94.901903        82.632845              16.562513   \n",
      "1      ESP        236.928941       158.752590              31.948041   \n",
      "2      GBR        201.837814       156.193379              31.538246   \n",
      "3      MCO        178.708344       171.391243              34.358199   \n",
      "\n",
      "   Mean curvature  Straight length [m]  Corner count  \n",
      "0        0.174331            64.919514           7.0  \n",
      "1        0.134308            58.981774           7.0  \n",
      "2        0.155108            59.452985           7.0  \n",
      "3        0.192143            60.597009          16.0  \n"
     ]
    }
   ],
   "source": [
    "map_file_list = glob.glob(f\"../../maps/*_centerline.csv\")\n",
    "\n",
    "map_data = []\n",
    "for map_file in map_file_list:\n",
    "    track = np.loadtxt(map_file, delimiter=',', skiprows=1)\n",
    "\n",
    "    map_name = map_file.split(\"/\")[-1].split(\"_\")[0]\n",
    "    el_lengths = np.linalg.norm(np.diff(track[:, :2], axis=0), axis=1)\n",
    "    track_length = np.sum(el_lengths)\n",
    "\n",
    "    psi, kappa = tph.calc_head_curv_num.calc_head_curv_num(track[:, :2], el_lengths, False)\n",
    "\n",
    "    total_curvature = np.sum(np.abs(kappa)) # consider integrating over distance...?\n",
    "    max_curvature = np.max(np.abs(kappa))\n",
    "    mean_curvature = np.mean(np.abs(kappa))\n",
    "\n",
    "    last_el = np.linalg.norm(track[0, :2] - track[-1, :2])\n",
    "    full_el = np.append(el_lengths, last_el)\n",
    "    straight_length = measure_straight_section(kappa, full_el)\n",
    "    corner_count, corner_crossings = count_corners(kappa)\n",
    "\n",
    "    corrected = kappa * full_el\n",
    "    total_corrected = np.sum(np.abs(corrected))\n",
    "\n",
    "    mini_dict = {\n",
    "        \"MapName\": map_name, \n",
    "        \"TrackLength\": track_length, \n",
    "        \"TotalCurvature\": total_curvature, \n",
    "        # \"TotalCorrected\": total_curvature * track_length,\n",
    "        \"TotalCorrected\": total_corrected,\n",
    "        \"MeanCurvature\": mean_curvature,\n",
    "    #  \"MaxCurvature\": max_curvature, \n",
    "        \"StraightLength\": straight_length/track_length*100,\n",
    "        \"CornerCount\": corner_count,\n",
    "        }\n",
    "    map_data.append(mini_dict)\n",
    "\n",
    "df = pd.DataFrame(map_data)\n",
    "df.CornerCount = df.CornerCount.astype(int)\n",
    "df = df.sort_values(by=[\"MapName\"])\n",
    "neat_names = [\"Map name\", \"Track length [m]\", \"Total curvature\", \"Total corrected [rad]\", \"Mean curvature\", \"Straight length [m]\", \"Corner count\"]\n",
    "# df.rename(columns=neat_names, inplace=True)\n",
    "df.rename(columns=dict(zip(df.columns, neat_names)), inplace=True)\n",
    "df = df.set_index('Map name', drop=True)\n",
    "# df.set_axis(neat_names, axis=1, inplace=True)\n",
    "df = df.T\n",
    "df.rename(columns=str.upper, inplace=True)\n",
    "#df.to_latex(\"../Data/MapInfo/MapTable.tex\", float_format=\"%.2f\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "map_df = df.T\n",
    "map_df = map_df.reset_index()\n",
    "print(map_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort(value):\n",
    "    numbers = re.findall(r'\\d+', value)\n",
    "    return int(numbers[-1]) if numbers else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8910b6a2b4430ba7a6a65b65a53257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=300, description='n', layout=Layout(width='800px'), max=1007), Output())â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Layout\n",
    "from scipy.signal import correlate, find_peaks\n",
    "\n",
    "def interpolate_track_new(points, n_points=None, s=0):\n",
    "    if len(points) <= 1:\n",
    "        return points\n",
    "    order_k = min(3, len(points) - 1)\n",
    "    tck = interpolate.splprep([points[:, 0], points[:, 1]], k=order_k, s=s)[0]\n",
    "    if n_points is None: n_points = len(points)\n",
    "    track = np.array(interpolate.splev(np.linspace(0, 1, n_points), tck)).T\n",
    "    return track\n",
    "\n",
    "def resample_track_points(points, seperation_distance=0.2, smoothing=0.2):\n",
    "    if points[0, 0] > points[-1, 0]:\n",
    "        points = np.flip(points, axis=0)\n",
    "\n",
    "    line_length = np.sum(np.linalg.norm(np.diff(points, axis=0), axis=1))\n",
    "    n_pts = max(int(line_length / seperation_distance), 2)\n",
    "    smooth_line = interpolate_track_new(points, None, smoothing)\n",
    "    resampled_points = interpolate_track_new(smooth_line, n_pts, 0)\n",
    "\n",
    "    return resampled_points, smooth_line\n",
    "\n",
    "def plot_with_slider(n):\n",
    "    # Load the boundary files based on the slider value for `n`\n",
    "    local_track = np.load(\"../../Logs/LocalMPCC/RawData_mu60/LocalMapData_mu60/local_map_\"+ str(n) +\".npy\")\n",
    "    print(f\"Local_track size: {local_track.shape}, length: {len(local_track)}\")\n",
    "    map_names = map_df[\"Map name\"].values\n",
    "\n",
    "    el_lengthsLocal = np.sqrt(np.sum(np.diff(local_track, axis=0)**2, axis=1))\n",
    "    psiLocal, kappaLocal = calc_head_curv_num(\n",
    "            path=local_track,\n",
    "            el_lengths=el_lengthsLocal,\n",
    "            is_closed=False,\n",
    "        )\n",
    "    map_names = [\"gbr\"]\n",
    "    for i, map_name in enumerate(map_names):\n",
    "        centre_line = CentreLine(map_name.lower(), directory=\"../../maps/\")  \n",
    "        track = centre_line\n",
    "        kappa = centre_line.kappa\n",
    "        resampled_points, smooth_line = resample_track_points(centre_line.path, seperation_distance=0.2, smoothing=0.5)\n",
    "        number_of_track_points = len(kappa)\n",
    "        print(f\"Number of track points: {number_of_track_points}\")\n",
    "        corner_count, corner_crossings = count_corners(kappa)\n",
    "        print(f\"Corner count: {corner_count}\")\n",
    "\n",
    "        last_el = np.linalg.norm(centre_line.path[0] - centre_line.path[-1])\n",
    "        full_el = np.append(centre_line.el_lengths, last_el)\n",
    "        straight_length = measure_straight_section(kappa, full_el)\n",
    "        print(f\"Straight length: {straight_length} m\")\n",
    "        \n",
    "        el_lengthsSmooth = np.sqrt(np.sum(np.diff(smooth_line, axis=0)**2, axis=1))\n",
    "        psiSmooth, kappaSmooth = calc_head_curv_num(\n",
    "                path=smooth_line,\n",
    "                el_lengths=el_lengthsSmooth,\n",
    "                is_closed=False,\n",
    "            )\n",
    "\n",
    "        el_lengthsSmooth2 = np.sqrt(np.sum(np.diff(resampled_points, axis=0)**2, axis=1))\n",
    "        print(f'Average lenght between points on resampled map: {np.mean(el_lengthsSmooth2)}')\n",
    "        print(f'Average lenght between points on local map: {np.mean(el_lengthsLocal)}')\n",
    "        psiSmooth2, kappaSmooth2 = calc_head_curv_num(\n",
    "                path=resampled_points,\n",
    "                el_lengths=el_lengthsSmooth2,\n",
    "                is_closed=False,\n",
    "            )\n",
    "        \n",
    "        start_index = n\n",
    "        \n",
    "        correlation_scores = np.correlate(np.flip(-kappaSmooth2), kappaLocal, mode='same')\n",
    "        print(f\"Corrleation scores lenght:{len(correlation_scores)}\")\n",
    "        min_score = np.min(correlation_scores)\n",
    "        shifted_scores = correlation_scores - min_score # Shift the scores to ensure all are positive (if necessary) >=0\n",
    "        normalized_scores = shifted_scores / np.max(shifted_scores) # Normalize the scores to a range between 0 and 1\n",
    "        probabilities = normalized_scores / np.sum(normalized_scores) # Convert to probabilities by dividing by the sum of the normalized scores\n",
    "        print(f\"Probabilities lenght: {len(probabilities)}\")\n",
    "        ma_sum = np.sum(probabilities) #Ensure probabilities sumise to 1\n",
    "        print(f\"Sum of probabilities: {ma_sum}\")\n",
    "        \n",
    "        # Replace negative values with zero\n",
    "        non_negative_scores = np.where(correlation_scores < 0, 0, correlation_scores)\n",
    "        probabilities = non_negative_scores / np.sum(non_negative_scores)\n",
    "       \n",
    "        \n",
    "        peaks, properties = find_peaks(correlation_scores, prominence=0.2)  # Adjust prominence as needed\n",
    "        estimated_position_peak = np.argmax(correlation_scores)       # Find the peak closest to the actual segment position (for visualization purposes)\n",
    "            \n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 8))\n",
    "     \n",
    "        end_index = start_index + len(kappaLocal)\n",
    "        axs[0].plot(kappa, label='Raw track Curvature') # This should be flipped\n",
    "        axs[0].plot(np.flip(-kappaSmooth2), label='Resampled track Curvature')\n",
    "        axs[0].plot(np.arange(start_index, end_index), kappaLocal, linewidth=2, label='Segment (Local Curvature)', color='red')\n",
    "        axs[0].set_xlim(0, number_of_track_points)\n",
    "        axs[0].set_title(f\"Curvature of '{map_name}' track\")\n",
    "        \n",
    "        shift_x = np.linspace(0, len(correlation_scores), len(correlation_scores))\n",
    "        axs[1].plot(shift_x, probabilities, label=\"Correlation Scores\", color='green')\n",
    "        axs[1].axvline(n, color='blue', linestyle='--', label='True Peak Position', linewidth=2)\n",
    "        axs[1].plot(peaks, probabilities[peaks], \"x\", label=\"Detected Peaks\", color='red')\n",
    "        axs[1].set_title(\"Correlation Scores by Sliding the Segment\")\n",
    "        axs[1].legend()\n",
    "        axs[1].set_xlim(0, number_of_track_points)\n",
    "        # axs[1].set_ylim(-1, 1)\n",
    "\n",
    "        points = track.path\n",
    "        axs[2].set_title(\"Track Points\")\n",
    "        axs[2].scatter(points[:, 0], points[:, 1], color='orange', label='Original Points', s =0.5)\n",
    "        l1 = track.path[:, :2] + track.nvecs * track.widths[:, 0][:, None]\n",
    "        l2 = track.path[:, :2] - track.nvecs * track.widths[:, 1][:, None]\n",
    "        axs[2].plot(l1[:, 0], l1[:, 1], color='black')\n",
    "        axs[2].plot(l2[:, 0], l2[:, 1], color='black')\n",
    "        for i, peak in enumerate(peaks):\n",
    "            axs[2].scatter(points[peak, 0], points[peak, 1], color='red', marker='*', s=100)\n",
    "        axs[2].scatter(points[estimated_position_peak, 0], points[estimated_position_peak, 1], color='green', label='Estimated Progress point', marker='*', s=100)\n",
    "        axs[2].scatter(points[n, 0], points[n, 1], color='blue', label='Progress point', marker='*', s=100)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create an interactive slider for `n` with a longer width\n",
    "slider = IntSlider(min=0, max=1007, step=1, value=300, layout=Layout(width='800px'))\n",
    "interact(plot_with_slider, n=slider);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F1T_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
